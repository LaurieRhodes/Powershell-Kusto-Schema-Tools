// ============================================================================
// Azure Data Explorer KQL Script for HDInsightSparkEnvironmentEvents - UPDATED VERSION
// ============================================================================
// Generated: 2025-09-14 10:15:31
// Table type: Microsoft
// Schema discovered using hybrid approach (Management API + getschema)
// Data type corrections applied: TenantId->guid, Double->real (empirical fixes)
// All columns including underscore columns included
// Original columns: 21, Final columns: 21
// ============================================================================

.create-merge table HDInsightSparkEnvironmentEventsRaw (records:dynamic)

.alter-merge table HDInsightSparkEnvironmentEventsRaw policy retention softdelete = 1d

.alter table HDInsightSparkEnvironmentEventsRaw policy caching hot = 1h

// JSON mapping - choose appropriate option based on data structure
.create-or-alter table HDInsightSparkEnvironmentEventsRaw ingestion json mapping 'HDInsightSparkEnvironmentEventsRawMapping' '[{"column":"records","Properties":{"path":"$.records"}}]'
// Alternative for direct events: '[{"column":"records","Properties":{"path":"$"}}]'

.create-merge table HDInsightSparkEnvironmentEvents(
TimeGenerated:datetime,
TenantId:guid,
IpAddress:string,
Region:string,
ClusterDnsName:string,
Host:string,
Role:string,
ClusterTenantId:string,
YarnQueue:string,
YarnTags:string,
SparkExecutorCores:int,
SparkExecutorMemory:string,
SparkExecutorInstances:int,
YarnMaxAttempts:int,
SparkMaster:string,
SparkDeployMode:string,
ApplicationId:string,
UserSubscriptionId:string,
SourceSystem:string,
Type:string,
_ResourceId:string,
_TimeReceived:datetime)

.alter table HDInsightSparkEnvironmentEvents policy caching hot = 1d

.create-or-alter function HDInsightSparkEnvironmentEventsExpand() {
HDInsightSparkEnvironmentEventsRaw
| mv-expand events = records
// Alternative for non-nested: | extend events = records
| project
TimeGenerated=todatetime(events.TimeGenerated),
TenantId=toguid(events.TenantId),
IpAddress=tostring(events.IpAddress),
Region=tostring(events.Region),
ClusterDnsName=tostring(events.ClusterDnsName),
Host=tostring(events.Host),
Role=tostring(events.Role),
ClusterTenantId=tostring(events.ClusterTenantId),
YarnQueue=tostring(events.YarnQueue),
YarnTags=tostring(events.YarnTags),
SparkExecutorCores=toint(events.SparkExecutorCores),
SparkExecutorMemory=tostring(events.SparkExecutorMemory),
SparkExecutorInstances=toint(events.SparkExecutorInstances),
YarnMaxAttempts=toint(events.YarnMaxAttempts),
SparkMaster=tostring(events.SparkMaster),
SparkDeployMode=tostring(events.SparkDeployMode),
ApplicationId=tostring(events.ApplicationId),
UserSubscriptionId=tostring(events.UserSubscriptionId),
SourceSystem=tostring(events.SourceSystem),
Type=tostring(events.Type),
_ResourceId=tostring(events._ResourceId),
_TimeReceived=todatetime(now())
}

.alter table HDInsightSparkEnvironmentEvents policy update @'[{"Source": "HDInsightSparkEnvironmentEventsRaw", "Query": "HDInsightSparkEnvironmentEventsExpand()", "IsEnabled": "True", "IsTransactional": true}]'
